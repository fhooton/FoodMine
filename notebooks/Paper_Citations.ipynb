{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook created by Forrest Hooton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import mfp\n",
    "from src.data_loader import load_ctd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Microsoft Academic Graph\n",
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Need to insert api key for Microsoft Academic Graph\n",
    "msft_apikey = 'Insert API key here as string'\n",
    "\n",
    "def get_title(ID):\n",
    "    # Mode can be 'calchistogram', 'evaluate', 'interpret', or 'similarity'\n",
    "    mode = 'evaluate'\n",
    "\n",
    "    headers = {\n",
    "        # Request headers\n",
    "        'Ocp-Apim-Subscription-Key': msft_apikey,\n",
    "    }\n",
    "    \n",
    "    params = urllib.parse.urlencode({\n",
    "        # Request parameters\n",
    "        'expr': f\"Id={ID}\",\n",
    "        'count': '10',\n",
    "        'model': 'latest',\n",
    "        'attributes': 'Ti',\n",
    "    })\n",
    "\n",
    "    loaded_eval = query_API(mode, params, headers)\n",
    "    \n",
    "    try:\n",
    "        title = loaded_eval['entities'][0]['Ti']\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    return title\n",
    "\n",
    "\n",
    "def get_citations(paper):\n",
    "    # Code snippits at: https://dev.labs.cognitive.microsoft.com/docs/services/56332331778daf02acc0a50b/operations/56332331778daf06340c9666\n",
    "\n",
    "    # Mode can be 'calchistogram', 'evaluate', 'interpret', or 'similarity'\n",
    "    mode = 'interpret'\n",
    "\n",
    "    query = paper\n",
    "\n",
    "    headers = {\n",
    "        # Request headers\n",
    "        'Ocp-Apim-Subscription-Key': msft_apikey,\n",
    "    }\n",
    "\n",
    "    params = urllib.parse.urlencode({\n",
    "        # Request parameters\n",
    "        'query': query,\n",
    "        'count': '10',\n",
    "        'model': 'latest',\n",
    "        'attributes': 'Ti',\n",
    "    })\n",
    "\n",
    "    loaded_eval = query_API(mode, params, headers)\n",
    "\n",
    "    # If there are issues with retrieving info, like no interpretations returned, return 0\n",
    "    try:\n",
    "        paper_query = loaded_interpret['interpretations'][0]['rules'][0]['output']['value']\n",
    "        ID, citations = __get_msft_attribute__(paper_query, 'RId', msft_apikey)\n",
    "    except:\n",
    "        return np.nan, []\n",
    "\n",
    "    return ID, citations\n",
    "\n",
    "# Gets a attribute from paper of Microsoft Academic Graph\n",
    "def __get_msft_attribute__(query, attr, key=msft_apikey):\n",
    "    # Mode can be 'calchistogram', 'evaluate', 'interpret', or 'similarity'\n",
    "    mode = 'evaluate'\n",
    "\n",
    "    headers = {\n",
    "        # Request headers\n",
    "        'Ocp-Apim-Subscription-Key': key,\n",
    "    }\n",
    "\n",
    "    params = urllib.parse.urlencode({\n",
    "        # Request parameters\n",
    "        'expr': query,\n",
    "        'count': '10',\n",
    "        'model': 'latest',\n",
    "        'attributes': attr,\n",
    "    })\n",
    "\n",
    "    loaded_eval = query_API(mode, params, headers)\n",
    "\n",
    "    # See for all attributes: https://docs.microsoft.com/en-us/azure/cognitive-services/academic-knowledge/paperentityattributes\n",
    "    ID = loaded_eval['entities'][0]['Id']\n",
    "    citations = loaded_eval['entities'][0][attr]\n",
    "\n",
    "    return ID, citations\n",
    "\n",
    "def query_API(mode, params, headers):\n",
    "    try:\n",
    "        conn = http.client.HTTPSConnection('api.labs.cognitive.microsoft.com')\n",
    "        conn.request(\"GET\", \"/academic/v1.0/\" + mode + \"?%s\" % params, \"{body}\", headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read()\n",
    "\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n",
    "        \n",
    "    return json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds citations and paper ID to dataframe\n",
    "# Target is the column that holds the paper titles\n",
    "def add_citations(df, target):\n",
    "    papers = pd.DataFrame({ target : df[df[target].notnull()][target].drop_duplicates().tolist() })\n",
    "    \n",
    "    citations_list = []\n",
    "    for idx, row in papers.iterrows():\n",
    "        ID, citations = get_citations(row[target])\n",
    "        \n",
    "        # Float implies that the ID is NaN, aka it did not recognize a paper\n",
    "        if isinstance(ID, float):\n",
    "            citations_list.append(np.nan)\n",
    "            continue\n",
    "        else:\n",
    "            papers.at[idx, 'paper_id'] = ID\n",
    "            citations_list.append(citations)\n",
    "    \n",
    "    papers['citations'] = citations_list\n",
    "    \n",
    "    return papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load FoodMine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_food_data = pd.read_pickle(mfp('misc_save/garlic_food_data.pkl'))\n",
    "g_food_info = pd.read_csv('data/garlic_scoring.csv', encoding='latin_1')\n",
    "\n",
    "c_food_data = pd.read_pickle(mfp('misc_save/cocoa_food_data.pkl'))\n",
    "c_food_info = pd.read_csv('data/cocoa_scoring.csv', encoding='latin_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all unique PMIDs and store into df\n",
    "g_PMIDs = pd.DataFrame({'PMID' : g_food_data.PMID.drop_duplicates().tolist()}).merge(g_food_info, how = 'left', on = 'PMID')[['PMID', 'paper']]\n",
    "c_PMIDs = pd.DataFrame({'PMID' : c_food_data.PMID.drop_duplicates().tolist()}).merge(c_food_info, how = 'left', on = 'PMID')[['PMID', 'paper']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 1] [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'data' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39046/576058552.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Retrieve citation ids from Microsoft Academic Graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mg_papers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_citations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_PMIDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'paper'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mc_papers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_citations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_PMIDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'paper'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#g_papers.to_pickle(mfp('misc_save/garlic_msft.pkl'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39046/1890607011.py\u001b[0m in \u001b[0;36madd_citations\u001b[0;34m(df, target)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcitations_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpapers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcitations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_citations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Float implies that the ID is NaN, aka it did not recognize a paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39046/2436934745.py\u001b[0m in \u001b[0;36mget_citations\u001b[0;34m(paper)\u001b[0m\n\u001b[1;32m     55\u001b[0m     })\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mloaded_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_API\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# If there are issues with retrieving info, like no interpretations returned, return 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39046/2436934745.py\u001b[0m in \u001b[0;36mquery_API\u001b[0;34m(mode, params, headers)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[Errno {0}] {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'data' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Retrieve citation ids from Microsoft Academic Graph\n",
    "g_papers = add_citations(g_PMIDs, 'paper')\n",
    "c_papers = add_citations(c_PMIDs, 'paper')\n",
    "\n",
    "#g_papers.to_pickle(mfp('misc_save/garlic_msft.pkl'))\n",
    "#c_papers.to_pickle(mfp('misc_save/cocoa_msft.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_citations = pd.read_pickle(mfp(f'misc_save/garlic_msft.pkl'))\n",
    "c_citations = pd.read_pickle(mfp(f'misc_save/cocoa_msft.pkl'))\n",
    "\n",
    "g_citation_ids = list(set([i for j in g_citations.citations.dropna().tolist() for i in j]))\n",
    "c_citation_ids = list(set([i for j in c_citations.citations.dropna().tolist() for i in j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 1] [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'data' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39046/2807372739.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg_citation_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtitles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39046/2436934745.py\u001b[0m in \u001b[0;36mget_title\u001b[0;34m(ID)\u001b[0m\n\u001b[1;32m     24\u001b[0m     })\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mloaded_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_API\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39046/2436934745.py\u001b[0m in \u001b[0;36mquery_API\u001b[0;34m(mode, params, headers)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[Errno {0}] {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'data' referenced before assignment"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Retrieve paper titles from MAG\n",
    "titles = []\n",
    "c = 0\n",
    "for p in g_citation_ids:\n",
    "    titles.append(get_title(p))\n",
    "    if not c % 3:\n",
    "        time.sleep(3)\n",
    "        \n",
    "    if not c % 50:\n",
    "        print(f'{c} at {(time.time()-start)/60} min')\n",
    "    c+=1\n",
    "\n",
    "#pd.DataFrame({'id' : g_citation_ids, 'title' : titles}).to_pickle(mfp('misc_save/garlic_citation_titles.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 1] [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'data' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39046/876643916.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc_citation_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtitles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39046/2436934745.py\u001b[0m in \u001b[0;36mget_title\u001b[0;34m(ID)\u001b[0m\n\u001b[1;32m     24\u001b[0m     })\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mloaded_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_API\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39046/2436934745.py\u001b[0m in \u001b[0;36mquery_API\u001b[0;34m(mode, params, headers)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[Errno {0}] {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'data' referenced before assignment"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Retrieve paper titles from MAG\n",
    "titles = []\n",
    "c = 0\n",
    "for p in c_citation_ids:\n",
    "    titles.append(get_title(p))\n",
    "    if not c % 3:\n",
    "        time.sleep(3)\n",
    "        \n",
    "    if not c % 50:\n",
    "        print(f'{c} at {(time.time()-start)/60} min')\n",
    "    c+=1\n",
    "\n",
    "#pd.DataFrame({'id' : c_citation_ids, 'title' : titles}).to_pickle(mfp('misc_save/cocoa_citation_titles.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ct = pd.read_pickle(mfp('misc_save/garlic_citation_titles.pkl'))\n",
    "c_ct = pd.read_pickle(mfp('misc_save/cocoa_citation_titles.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions are generally the same as misc/pubmed_utils.py, but slightly tweaked\n",
    "\n",
    "import urllib.request as request\n",
    "from lxml import etree\n",
    "import math\n",
    "\n",
    "# Constructs appropriate url for pubmed api from search terms\n",
    "def __construct_url__(url_input, query_type, num_results = 1000000):\n",
    "\n",
    "    # Constructs url for search query\n",
    "    if query_type == 'search':\n",
    "        base_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term='\n",
    "        \n",
    "        if isinstance(url_input, str):\n",
    "            term_url = url_input.replace(\" \", \"%20\")\n",
    "        else:\n",
    "            adjusted_terms = [s.replace(\" \", \"%20\") for s in url_input]\n",
    "            term_url = '%20AND%20'.join(adjusted_terms)\n",
    "\n",
    "        url = base_url + term_url\n",
    "        return url\n",
    "\n",
    "    elif query_type == 'document':\n",
    "        base_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id='\n",
    "\n",
    "        doc_urls = \"\"\n",
    "        for i in url_input:\n",
    "            if isinstance(i, str): \n",
    "                doc_urls = doc_urls + \",\" + i\n",
    "            else:\n",
    "                doc_urls = doc_urls + \",\" + str(i)\n",
    "\n",
    "        url = base_url + doc_urls.lstrip(\",\") + '&retmode=xml'\n",
    "\n",
    "        return url\n",
    "\n",
    "\n",
    "# Divides doc ids for larger paper queries in retrieve_doc_info()\n",
    "def __divide_list__(ids, num_divisions):\n",
    "\n",
    "    split_ids = np.array_split(np.asarray(ids), num_divisions)\n",
    "    split_ids = [np.ndarray.tolist(split_ids[i]) for i in range(len(split_ids))]\n",
    "\n",
    "    return split_ids\n",
    "\n",
    "# Enters search terms into pubmed database to return document ID's\n",
    "def search_pubmed(search_term):\n",
    "\n",
    "    url = __construct_url__(search_term, 'search')\n",
    "    \n",
    "    with request.urlopen(url) as response:\n",
    "        xml = response.read()\n",
    "\n",
    "    root = etree.fromstring(xml)\n",
    "\n",
    "    # Recursively gets all objects where the tag is Id\n",
    "    if (root.findall('.//Count') is None) | (root.findall('.//Count')[0].text == '0'):\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    elements = root.findall('.//Count')\n",
    "    \n",
    "    ID = root.findall('.//Id')[0].text\n",
    "    \n",
    "\n",
    "    # Converts all lxml objects to their text values\n",
    "    ids = [i.text for i in elements]\n",
    "\n",
    "    return ids[0], ID\n",
    "\n",
    "# Retrieves document (paper) info using pubmed paper ids\n",
    "def retrieve_doc_info(ids):\n",
    "    # Can't query too many id's in a single query, so divides larger id lists into separate queries\n",
    "    num_loops = int(math.ceil(len(ids) / 100))\n",
    "\n",
    "    # Have to split requests larger than 100 documents to keep it within url size\n",
    "    ids = __divide_list__(ids, num_loops)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # Retrieves xml data from pubmed\n",
    "    for i in ids:\n",
    "        url = self.__construct_url__(i, 'document')\n",
    "\n",
    "        with request.urlopen(url) as response:\n",
    "            xml = response.read()\n",
    "\n",
    "        root = etree.fromstring(xml)\n",
    "\n",
    "        documents = documents + root.findall('PubmedArticle')\n",
    "\n",
    "    info = pd.DataFrame()\n",
    "\n",
    "    for document in documents:\n",
    "\n",
    "        doc_id = int(document.find('.//PMID').text)\n",
    "\n",
    "        paper = document.find('.//ArticleTitle').text\n",
    "\n",
    "        journal = document.find('.//Title').text\n",
    "\n",
    "        year = document.find('.//Year').text\n",
    "\n",
    "        if document.find('.//AbstractText') is not None:\n",
    "            abstract = document.find('.//AbstractText').text\n",
    "        else:\n",
    "            abstract = None\n",
    "\n",
    "        mesh_terms = []\n",
    "        mesh_UIds = []\n",
    "        qual_terms = []\n",
    "        qual_UIds = []\n",
    "\n",
    "        for mesh_section in document.findall('.//MeshHeading'):\n",
    "            mesh_terms.append(mesh_section.find('.//DescriptorName').text)\n",
    "            mesh_UIds.append(mesh_section.find('.//DescriptorName').attrib['UI'])\n",
    "\n",
    "            if mesh_section.find('.//QualifierName') is not None:\n",
    "                qual_terms.append(mesh_section.find('.//QualifierName').text)\n",
    "                qual_UIds.append(mesh_section.find('.//QualifierName').attrib['UI'])\n",
    "            else:\n",
    "                qual_terms.append(None)\n",
    "                qual_UIds.append(None)\n",
    "\n",
    "        new_row = {\n",
    "            'PMID' : doc_id,\n",
    "            'paper' : paper,\n",
    "            'journal' : journal,\n",
    "            'year' : year,\n",
    "            'abstract' : abstract,\n",
    "            'mesh_terms' : mesh_terms,\n",
    "            'mesh_UIds' : mesh_UIds,\n",
    "            'qual_terms' : qual_terms,\n",
    "            'qual_UIds' : qual_UIds,\n",
    "            'webpage' : 'https://www.ncbi.nlm.nih.gov/pubmed/' + str(doc_id)\n",
    "        }\n",
    "\n",
    "        info = info.append(new_row, ignore_index = True)\n",
    "\n",
    "    info['PMID'] = info['PMID'].astype('int32')\n",
    "\n",
    "    return info.reset_index(drop = True)\n",
    "\n",
    "def greek_letter_converter(chem):\n",
    "    chem = chem.replace('α ', 'alpha-')\n",
    "    chem = chem.replace('β ', 'beta-')\n",
    "    chem = chem.replace('γ ', 'gamma-')\n",
    "    chem = chem.replace('ρ ', 'rho-')\n",
    "    chem = chem.replace('δ ', 'delta-')\n",
    "\n",
    "    return chem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 at 0.047705264886220296 min\n"
     ]
    }
   ],
   "source": [
    "g_ct.title = g_ct.title.apply(greek_letter_converter)\n",
    "\n",
    "# Query pubmed with titles to find PMID\n",
    "start = time.time()\n",
    "c=0\n",
    "for idx, row in g_ct.iterrows():\n",
    "    try:\n",
    "        _, ID = search_pubmed(row['title'])\n",
    "        g_ct.at[idx, 'pubmed_id'] = ID\n",
    "        time.sleep(.5)\n",
    "    except:\n",
    "        g_ct.at[idx, 'pubmed_id'] = 0\n",
    "        pass\n",
    "    \n",
    "    if not c % 50:\n",
    "        print(f'{c} at {(time.time()-start)/60} min')\n",
    "    c+=1\n",
    "    \n",
    "#g_ct.to_pickle(mfp('misc_save/garlic_citation_PMIDs.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_ct.title = c_ct.title.apply(greek_letter_converter)\n",
    "\n",
    "# Query pubmed with titles to find PMID\n",
    "start = time.time()\n",
    "c=0\n",
    "for idx, row in c_ct.iterrows():\n",
    "    try:\n",
    "        _, ID = search_pubmed(row['title'])\n",
    "        g_ct.at[idx, 'pubmed_id'] = ID\n",
    "        time.sleep(.5)\n",
    "    except:\n",
    "        g_ct.at[idx, 'pubmed_id'] = 0\n",
    "        pass\n",
    "    \n",
    "    if not c % 50:\n",
    "        print(f'{c} at {(time.time()-start)/60} min')\n",
    "    c+=1\n",
    "    \n",
    "#c_ct.to_pickle(mfp('misc_save/cocoa_citation_PMIDs.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ct = pd.read_pickle(mfp('misc_save/garlic_citation_PMIDs.pkl'))\n",
    "c_ct = pd.read_pickle(mfp('misc_save/cocoa_citation_PMIDs.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in CTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\forresthooton\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "hdata = load_ctd()\n",
    "\n",
    "de_health = pd.DataFrame(\n",
    "    hdata[hdata.pubchem_id.notnull() & hdata.PubMedIDs.notnull()][['pubchem_id', 'PubMedIDs', 'ChemicalName']]\n",
    "    .groupby(['pubchem_id','PubMedIDs']).count()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65016"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(de_health.PubMedIDs.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_fm = pd.read_pickle(mfp('misc_save/garlic_food_data.pkl'))\n",
    "c_fm = pd.read_pickle(mfp('misc_save/cocoa_food_data.pkl'))\n",
    "\n",
    "# Use papers for CTD compounds that appear in the food pilots\n",
    "g_fm = g_fm.merge(de_health, how='inner', on = 'pubchem_id')\n",
    "c_fm = c_fm.merge(de_health, how='inner', on = 'pubchem_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_papers_g = pd.DataFrame({'PMID' : list(set([int(i) for j in g_fm.PubMedIDs.dropna().str.split('|').tolist() for i in j]))})\n",
    "h_papers_c = pd.DataFrame({'PMID' : list(set([int(i) for j in c_fm.PubMedIDs.dropna().str.split('|').tolist() for i in j]))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Paper Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PMID, index]\n",
       "Index: []"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = h_papers_g.merge(pd.DataFrame(g_food_data.PMID.drop_duplicates().reset_index()), how='inner')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PMID, index]\n",
       "Index: []"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = h_papers_c.merge(pd.DataFrame(c_food_data.PMID.drop_duplicates().reset_index()), how='inner')\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23430952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID\n",
       "0  23430952"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_list = g_ct[g_ct.pubmed_id.notnull()].pubmed_id.apply(int).tolist()\n",
    "\n",
    "g_cda = pd.DataFrame({'PMID' : g_list})\n",
    "\n",
    "g_overlap = h_papers_g.merge(g_cda, how='inner')\n",
    "g_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30336258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID\n",
       "0  30336258"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_list = c_ct[c_ct.pubmed_id.notnull()].pubmed_id.apply(int).tolist()\n",
    "\n",
    "c_cda = pd.DataFrame({'PMID' : c_list})\n",
    "\n",
    "c_overlap = h_papers_c.merge(c_cda, how='inner')\n",
    "c_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
